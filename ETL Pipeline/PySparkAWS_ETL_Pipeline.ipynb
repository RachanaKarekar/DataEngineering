{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySparkAWS_ETL_Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMaW3RQdayOM"
      },
      "source": [
        "!wget https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_5ifbtGbI48"
      },
      "source": [
        "!tar -xvf spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7l94hZTbM7R"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1Wp402jbRgY"
      },
      "source": [
        "!pip install findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptySKroxbl2Z"
      },
      "source": [
        "!wget \"https://raw.githubusercontent.com/AISCIENCES/course-master-big-data-with-pyspark-and-aws/main/Code/06-ETL/WordData.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUcHjXL6bVJc"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"ETL\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4wJkkQ1arGP"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnMfFJFydhMC"
      },
      "source": [
        "from pyspark.sql.functions import col, lit, explode\n",
        "import pyspark.sql.functions as f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKgjITa0cEoF"
      },
      "source": [
        "# **Extract**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyM7GeLZcHc4",
        "outputId": "6b930731-c512-4252-92c6-48e63f3daa45"
      },
      "source": [
        "df = spark.read.text(\"/content/WordData.txt\")\n",
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|               value|\n",
            "+--------------------+\n",
            "|This is a Japanes...|\n",
            "|The team members ...|\n",
            "|As the years pass...|\n",
            "|If you don't like...|\n",
            "|He was disappoint...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT_5YepAcyBq"
      },
      "source": [
        "# **Transform**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuuFaxFgc0gv",
        "outputId": "ec8f20e9-ce98-44db-8fa7-fadd6a887f81"
      },
      "source": [
        "wordsDF = df.withColumn(\"splitted_data\", f.split(\"value\", \" \")).withColumn(\"words\", explode(col(\"splitted_data\"))).select(col(\"words\"))\n",
        "wordsDF.cache()\n",
        "wordsDF.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+\n",
            "|   words|\n",
            "+--------+\n",
            "|    This|\n",
            "|      is|\n",
            "|       a|\n",
            "|Japanese|\n",
            "|    doll|\n",
            "|     The|\n",
            "|    team|\n",
            "| members|\n",
            "|    were|\n",
            "|    hard|\n",
            "|      to|\n",
            "|    tell|\n",
            "|   apart|\n",
            "|   since|\n",
            "|    they|\n",
            "|     all|\n",
            "|    wore|\n",
            "|   their|\n",
            "|    hair|\n",
            "|      in|\n",
            "+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK1hC2T_heMM"
      },
      "source": [
        "Word Count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpyeghLVhhiC",
        "outputId": "dc38217f-cea7-4329-d744-e09b106b3603"
      },
      "source": [
        "wordCountDF = wordsDF.groupBy(\"words\").count()\n",
        "wordCountDF.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+-----+\n",
            "|      words|count|\n",
            "+-----------+-----+\n",
            "|   Tomorrow|    4|\n",
            "|         If|    8|\n",
            "|      leave|    4|\n",
            "|      corny|    4|\n",
            "|        day|    4|\n",
            "|preoccupied|    4|\n",
            "|       even|    8|\n",
            "|      crazy|    4|\n",
            "|    bananas|    4|\n",
            "|     priest|    4|\n",
            "|        did|    4|\n",
            "|    whether|    4|\n",
            "|     Having|    4|\n",
            "|        I'm|    4|\n",
            "|      crime|    4|\n",
            "|  surprised|    4|\n",
            "|      James|    4|\n",
            "|      could|    8|\n",
            "|        buy|    4|\n",
            "|        him|    8|\n",
            "+-----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6TykXC3l-JP"
      },
      "source": [
        "# **Load**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkUnTZaGmAos"
      },
      "source": [
        "driver = \"org.postgresql.Driver\"\n",
        "url = \"jdbc:postgresql://database-1.c0sanhk4hmut.us-west-2.rds.amazonaws.com/\"\n",
        "table = \"WordCount\"\n",
        "user = \"postgres\"\n",
        "password = \"\"\n",
        "\n",
        "wordCount.write.format(\"jdbc\").option(\"driver\", driver).option(\"url\",url).option(\"dbtable\", table).option(\"mode\", \"append\").option(\"user\",user).option(\"password\", password).save()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}